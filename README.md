# Sparsity.jl
Repository with Julia code used in Master's Thesis.
All script are available on master branch.

# FIRST EXPERIMENT - Sparse Regression, Sparse Regression L1, v_optimizer

* Part 1 - classic pipeline for ML in Julia language to train and validate model.
* Part 2 - L1 regularization with Pareto frontiers.
* Part 3 - variational methods applied to this experiment in order to find sparse solutions.

# SECOND EXPERIMENT - Iris Various

* same methods from experiment 1 applied to the Iris problem. Classification on deeper neural network with trying to prune it.

# THIRD EXPERIMENT - Mill

* same methods applied to multi-instance learning experiment with the Musk dataset. Again, the main goal of this experiment, is to prune this deep neural network to make it more interpretable.
